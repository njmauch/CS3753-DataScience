{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67105263]\n",
      "[[0.81578947]]\n",
      "Linear Regression A: 0.25\n",
      "Linear Regression B: 1.50\n",
      "Linear Regression C: 0.54\n",
      "Linear Regression D: 0.06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import sqrt\n",
    "import pdb\n",
    "from csv import reader\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "##%% Question 1\n",
    "x = np.array([0.5, 2, 3])\n",
    "y = np.array([1, 2.5, 3])\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model = model.fit(x.reshape(-1,1), y.reshape(-1,1))\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)\n",
    "\n",
    "slope = 1\n",
    "intercept = 0.5\n",
    "SSE1 = ((y - (intercept + (slope * x))).dot(y- (intercept + (slope * x))))\n",
    "slope = 1\n",
    "intercept = 1\n",
    "SSE2 = ((y - (intercept + (slope * x))).dot(y- (intercept + (slope * x))))\n",
    "slope = 0.8\n",
    "intercept = 0.3\n",
    "SSE3 = ((y - (intercept + (slope * x))).dot(y- (intercept + (slope * x))))\n",
    "slope = 0.8\n",
    "intercept = 0.7\n",
    "SSE4 = ((y - (intercept + (slope * x))).dot(y- (intercept + (slope * x))))\n",
    "\n",
    "print(\"Linear Regression A: {:0.2f}\".format(SSE1))\n",
    "print(\"Linear Regression B: {:0.2f}\".format(SSE2))\n",
    "print(\"Linear Regression C: {:0.2f}\".format(SSE3))\n",
    "print(\"Linear Regression D: {:0.2f}\".format(SSE4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 2\n",
      "2. Ridge and lasso regression are simple techniques to prevent overfitting in linear regression\n",
      "Ridge regression can provide better long-term predictions and does better when most variables are useful\n",
      "Lasso regression is less likely to overfit and better prediction performance on new data. It can also exclude useless variables from equations\n"
     ]
    }
   ],
   "source": [
    "##%% Question 2\n",
    "print(\"\\nQuestion 2\")\n",
    "print(\"2. Ridge and lasso regression are simple techniques to prevent overfitting in linear regression\")\n",
    "print(\"Ridge regression can provide better long-term predictions and does better when most variables are useful\")\n",
    "print(\"Lasso regression is less likely to overfit and better prediction performance on new data. It can also exclude useless variables from equations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Question 3\n",
      "Split A:\n",
      "Parent Node Gini = 0.444\n",
      "Gini Children = 0.213\n",
      "Information gain = 0.408\n",
      "The split error = 0.200\n",
      "Split B:\n",
      "Parent Node Gini = 0.444\n",
      "Gini Children = 0.444\n",
      "Information gain = 0.000\n",
      "The split error = 0.000\n",
      "Split C:\n",
      "Parent Node Gini = 0.444\n",
      "Gini Children = 0.180\n",
      "Information gain = 0.450\n",
      "The split error = 0.233\n",
      "The conclusion is that split C had the best results for all 3 methods, it had the lowest value for the gini index, 0.180, and the highest values for the information gain, 0.450, and split error, 0.233\n"
     ]
    }
   ],
   "source": [
    "##%% Question 3\n",
    "print(\"\\n\\nQuestion 3\")\n",
    "def gini(node):\n",
    "    total = node[\"C1\"] + node[\"C2\"]\n",
    "    return 1 - (node[\"C1\"]/total)**2 - (node[\"C2\"]/total)**2\n",
    "def giniChildren(node1, node2, gini_n1, gini_n2):\n",
    "    total_n1 = node1[\"C1\"] + node1[\"C2\"]\n",
    "    total_n2 = node2[\"C1\"] + node2[\"C2\"]\n",
    "    return (total_n1/(total_n1 + total_n2) * gini_n1) + (total_n2/(total_n1 + total_n2) * gini_n2)\n",
    "def entropy(node):\n",
    "    total = node[\"C1\"] + node[\"C2\"]\n",
    "    return (-(node[\"C1\"]/total) * np.log2(node[\"C1\"]/total)) - ((node[\"C2\"]/total) * np.log2(node[\"C2\"]/total))\n",
    "def gain(ent_parent, ent_n1, ent_n2, node1, node2):\n",
    "    total_n1 = node1[\"C1\"] + node1[\"C2\"]\n",
    "    total_n2 = node2[\"C1\"] + node2[\"C2\"]\n",
    "    n = total_n1 + total_n2\n",
    "    return ent_parent - (total_n1/n * ent_n1 + total_n2/n * ent_n2)\n",
    "def error(node):\n",
    "    total = node[\"C1\"] + node[\"C2\"]\n",
    "    p_c1 = node[\"C1\"]/total\n",
    "    p_c2 = node[\"C2\"]/total\n",
    "    return 1.0 - np.max([p_c1, p_c2])\n",
    "def split_error(err_parent, err_n1, err_n2, node1, node2, parent_node):\n",
    "    total_parent = parent_node[\"C1\"] + parent_node[\"C2\"]\n",
    "    total_n1 = node1[\"C1\"] + node1[\"C2\"]\n",
    "    total_n2 = node2[\"C1\"] + node2[\"C2\"]\n",
    "    return err_parent - (total_n1/total_parent * err_n1 + total_n2/total_parent * err_n2)\n",
    "\n",
    "A = {\"Parent\": {\"C1\": 20, \"C2\": 10}, \"Node N1\": {\"C1\": 3, \"C2\": 9}, \"Node N2\": {\"C1\": 17, \"C2\": 1}}\n",
    "B = {\"Parent\": {\"C1\": 20, \"C2\": 10}, \"Node N1\": {\"C1\": 10, \"C2\": 5}, \"Node N2\": {\"C1\": 10, \"C2\": 5}}\n",
    "C = {\"Parent\": {\"C1\": 20, \"C2\": 10}, \"Node N1\": {\"C1\": 19, \"C2\": 2}, \"Node N2\": {\"C1\": 1, \"C2\": 8}}\n",
    "print(\"Split A:\")\n",
    "gini_parent = gini(A[\"Parent\"])\n",
    "entropy_parent = entropy(A[\"Parent\"])\n",
    "error_parent = error(A[\"Parent\"])\n",
    "print(\"Parent Node Gini = {:0.3f}\".format(gini_parent))\n",
    "gini_n1 = gini(A[\"Node N1\"])\n",
    "entropy_n1 = entropy(A[\"Node N1\"])\n",
    "error_n1 = error(A[\"Node N1\"])\n",
    "gini_n2 = gini(A[\"Node N2\"])\n",
    "entropy_n2 = entropy(A[\"Node N2\"])\n",
    "error_n2 = error(A[\"Node N2\"])\n",
    "gini_children = giniChildren(A[\"Node N1\"], A[\"Node N2\"], gini_n1, gini_n2)\n",
    "print(\"Gini Children = {:0.3f}\".format(gini_children))\n",
    "entropy_gain = gain(entropy_parent, entropy_n1, entropy_n2, A[\"Node N1\"], A[\"Node N2\"])\n",
    "error_split_a = split_error(error_parent, error_n1, error_n2, A[\"Node N1\"], A[\"Node N2\"], A[\"Parent\"])\n",
    "print(\"Information gain = {:0.3f}\".format(entropy_gain))\n",
    "print(\"The split error = {:0.3f}\".format(error_split_a))\n",
    "\n",
    "print(\"Split B:\")\n",
    "gini_parent = gini(B[\"Parent\"])\n",
    "entropy_parent = entropy(B[\"Parent\"])\n",
    "error_parent = error(B[\"Parent\"])\n",
    "print(\"Parent Node Gini = {:0.3f}\".format(gini_parent))\n",
    "gini_n1 = gini(B[\"Node N1\"])\n",
    "entropy_n1 = entropy(B[\"Node N1\"])\n",
    "error_n1 = error(B[\"Node N1\"])\n",
    "gini_n2 = gini(B[\"Node N2\"])\n",
    "entropy_n2 = entropy(B[\"Node N2\"])\n",
    "error_n2 = error(B[\"Node N2\"])\n",
    "gini_children = giniChildren(B[\"Node N1\"], B[\"Node N2\"], gini_n1, gini_n2)\n",
    "print(\"Gini Children = {:0.3f}\".format(gini_children))\n",
    "entropy_gain = gain(entropy_parent, entropy_n1, entropy_n2, B[\"Node N1\"], B[\"Node N2\"])\n",
    "error_split_b = split_error(error_parent, error_n1, error_n2, B[\"Node N1\"], B[\"Node N2\"], B[\"Parent\"])\n",
    "print(\"Information gain = {:0.3f}\".format(entropy_gain))\n",
    "print(\"The split error = {:0.3f}\".format(error_split_b))\n",
    "\n",
    "print(\"Split C:\")\n",
    "gini_parent = gini(C[\"Parent\"])\n",
    "entropy_parent = entropy(C[\"Parent\"])\n",
    "error_parent = error(C[\"Parent\"])\n",
    "print(\"Parent Node Gini = {:0.3f}\".format(gini_parent))\n",
    "gini_n1 = gini(C[\"Node N1\"])\n",
    "entropy_n1 = entropy(C[\"Node N1\"])\n",
    "error_n1 = error(C[\"Node N1\"])\n",
    "gini_n2 = gini(C[\"Node N2\"])\n",
    "entropy_n2 = entropy(C[\"Node N2\"])\n",
    "error_n2 = error(C[\"Node N2\"])\n",
    "gini_children = giniChildren(C[\"Node N1\"], C[\"Node N2\"], gini_n1, gini_n2)\n",
    "print(\"Gini Children = {:0.3f}\".format(gini_children))\n",
    "entropy_gain = gain(entropy_parent, entropy_n1, entropy_n2, C[\"Node N1\"], C[\"Node N2\"])\n",
    "error_split_c = split_error(error_parent, error_n1, error_n2, C[\"Node N1\"], C[\"Node N2\"], C[\"Parent\"])\n",
    "print(\"Information gain = {:0.3f}\".format(entropy_gain))\n",
    "print(\"The split error = {:0.3f}\".format(error_split_c))\n",
    "print(\"The conclusion is that split C had the best results for all 3 methods, it had the lowest value for the gini index, 0.180, and the highest values for the information gain, 0.450, and split error, 0.233\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 4\n",
      "Class Iris-versicolor ID => 0\n",
      "Class Iris-setosa ID => 1\n",
      "Class Iris-virginica ID => 2\n",
      "Scores: [96.66666666666667, 96.66666666666667, 100.0, 90.0, 100.0]\n",
      "Mean Accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "# Load a CSV file\n",
    "print(\"Question 4\")\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "        print('Class %s ID => %d' % (value, i))\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "\n",
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "\n",
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    ### your code starts\n",
    "    distance = 0.0\n",
    "    for x in range(len(row1) - 1):\n",
    "        distance += (row1[x] - row2[x])**2\n",
    "    ### your code ends\n",
    "    return sqrt(distance)\n",
    "\n",
    "\n",
    "# Locate the most similar neighbors and return the list of neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    ### your code starts\n",
    "    distances = []\n",
    "    for train_row in train:\n",
    "        distances.append((train_row, euclidean_distance(test_row, train_row)))\n",
    "    distances.sort(key=lambda distance: distance[1])\n",
    "    neighbors = []\n",
    "    for x in range(num_neighbors):\n",
    "        neighbors.append(distances[x][0])\n",
    "    ### your code ends\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "# Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    ### your code starts\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output = []\n",
    "    for row in neighbors:\n",
    "        output.append(row[-1])\n",
    "    prediction = max(set(output), key=output.count)\n",
    "    ### your code ends\n",
    "    return prediction\n",
    "\n",
    "\n",
    "# kNN Algorithm\n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_classification(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return (predictions)\n",
    "\n",
    "\n",
    "# Test the kNN on the Iris Flowers dataset\n",
    "seed(1)\n",
    "filename = 'iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0]) - 1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores) / float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
